---
layout:     post                    # 使用的布局（不需要改）
title:      FireCNN学习研究          # 标题 
subtitle:   火焰识别                 #副标题
date:       2019-04-26              # 时间
author:     KW                      # 作者
header-img: img/post-cat3.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 机器学习
---

> 今天来学习一下z这篇火焰识别的论文([FireCNN](https://breckon.org/toby/publications/papers/dunnings18fire.pdf))

### 基于CNN的实时视频火焰检测

这是一篇October 7-10, 2018.发表于 IEEE International Conference on Image Processing (ICIP) 的一篇文章

### 摘要

作者研究了在不依赖于时间场景信息的情况下，在实时界限内自动检测视频（或静止）图像中的火像素区域。考虑实验的性能，作者通过降低复杂度的深度卷积神经网络（CNN）架构完成这项任务。与现场的当代趋势相反，结果表明整个图像二元火灾检测的最大准确度为0.93，通过复杂性显着降低的网络架构，在超像素定位框架内可以达到0.89的准确度。这些简化的架构还提供了3-4倍的计算性能提升，在当代硬件上提供高达17 fps的处理性能。使用基准数据集得到相当的性能(说明先前的工作不一定是对的)，以得到最大限度的实时火灾区域检测。

### 正文

首先介绍了目前火灾检测的用途十分广泛，可以被用在公共安全未来还可能用于交通工具中。

其次介绍了传统的火灾检测方法：

1. purely colour based approach
2. a combination of colour and high-order temporal information

之前的工作主要关注点在颜色域上，后来关注火焰的变化，上升到傅里叶域，未来将上升到Hidden Markov Model problem（馬可夫模型）。  
传统的方法，In general these works report ~98-99% (truepositive) detection at 10-40 frames per second (fps) on relatively  small image sizes。（这种利用颜色模型的方法真的有这么高么？）  
作者将机器学习的分类方法用于火焰检测问题。说以前方法大多都基于火焰动态和运动特性来检测的，本文提出一种不需要考虑上下文信息的方案。

### 方法

+ 使用了低复杂度的CNN网络结构
+ operating on single image inputs (non-temporal) experimentally optimized for the fire detection task  不依赖于上下文信息的检测
+ This is then expanded into a superpixel based localization approach to offer a complete detection solution 将其推广至超像素中，提供一个完整的检测方法。

### 网络结构

作者对 AlexNet，VGG16 和 Inception 网络进行了对比选择，最终作者通过不知道什么实验，确认了 AlexNet 和 Inception 网络更好。

对于AlexNet，考虑了六种不同的情况：  
C1-C6 as follows: C1 removed layer 3  only, C2 removed layers 3，4。C3 removed layers 3; 4; 5 , C4removed layers 6  only, C5 removed layers 3; 4; 6  and C6 removed layer 2  only. C7表示没改动的AlexNet。结果如下图左所示：

![AlexNet](http://pqcapse3i.bkt.clouddn.com/AlexNet.png)

对于InceptionV1，有八种情况，we consider eight variationsto the architectural configuration by removing up to 8 inception modules from the original configuration of 9 present。结果如右图所示，9表示未删减版。

从图中能看出，C2准确率高且相对参数较少，右图3便显得较好，only three inception modules is the variation with the fewest parameters which retains performance in the highest band。

作者使用了25%的训练集，发现CNN的C2和AlexNet的C7会产生过拟合，且随着复杂度增加也会产生过拟合所以作者提出来了下面的网络

![fireNet](http://prfm9pn5e.bkt.clouddn.com/FireNet.png)

#### 超级像素superpixel定位

结合了传统的方法，不多说了

![superpixel](http://prfm9pn5e.bkt.clouddn.com/superFireNet.png)

关于实验结果直接看我下面的翻译吧  
结论就是速度快，精度高

[下载翻译](http://prfm9pn5e.bkt.clouddn.com/FireNet.docx)