---
layout:     post                    # 使用的布局
title:      操作系统基本功能 -- 内存管理          # 标题 
subtitle:   内存分配、内存保护与共享、地址映射、虚拟内存等等       #副标题
date:       2019-06-01              # 时间
author:     KW                      # 作者
header-img: img/两杆大烟枪.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 操作系统
---

### 内存管理

总的来说，包括内存管理和虚拟内存管理。  
内存管理包括程序装入等概念、交换技术、连续分配管理方式和非连续分配管理方式（分页、分段、段页式）。  
虚拟内存管理包括虚拟内存概念、请求分页管理方式、页面置换算法、页面分配策略、工作集和抖动。

#### 存储器层次结构

寄存器 -- 高速缓存 -- 主存储器 -- 磁盘缓存 -- 固定磁盘 -- 可移动存储介质

#### 程序装入和链接

创建进程首先要将程序和数据装入内存。将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤：

+ 编译：由编译程序将用户源代码编译成若干个目标模块。
+ 链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块。
+ 装入：由装入程序将装入模块装入内存运行。  
![对用户程序的处理步骤](https://upload-images.jianshu.io/upload_images/17260324-d559464f8c820f06.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

程序的链接方式：

+ 静态链接：在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。
+ 装入时动态链接：将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接的链接方式。
+ 运行时动态链接：对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链接。其优点是便于修改和更新，便于实现对目标模块的共享。

程序的装入方式：

1. **绝对装入**：在编译时，如果知道程序将驻留在内存的某个位置，编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，故不需对程序和数据的地址进行修改。
2. **可重定位装入**：在多道程序环境下，多个目标模块的起始地址通常都是从 0 开始，程序中的其他地址都是相对于起始地址的,此时应釆用可重定位装入方式。根据内存的当前情况，将装入模块装入到内存的适当位置。装入时对目标程序中指令和数据的修改过程称为重定位，地址变换通常是在装入时一次完成的，所以又称为静态重定位。  
静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内存空间。
3. **动态运行时装入，也称为动态重定位**：程序在内存中如果发生移动，就需要釆用动态的装入方式。装入程序在把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。这种方式需要一个重定位寄存器的支持。  
动态重定位的特点是可以将程序分配到不连续的存储区中；在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。  
![重定向类型](https://upload-images.jianshu.io/upload_images/17260324-f1bfa411e3a812d7.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

#### 内存保护

内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。通过釆用重定位寄存器和界地址寄存器来实现这种保护。重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址值。  
每个逻辑地址值必须小于界地址寄存器；内存管理机构动态地将逻辑地址与界地址寄存器进行比较，如果未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元。  
当CPU调度程序选择进程执行时，派遣程序会初始化重定位寄存器和界地址寄存器。每一个逻辑地址都需要与这两个寄存器进行核对，以保证操作系统和其他用户程序及数据不被该进程的运行所影响。

#### 内存交换

交换（对换）的基本思想是，把处于等待状态（或在 CPU 调度原则下被剥夺运行权利）的程序从内存移到辅存，把内存空间腾出来，这一过程又叫换出；把准备好竞争 CPU 运行的程序从辅存移到内存，这一过程又称为换入。中级调度就是釆用交换技术。

注意一下问题：

+ 交换需要备份存储，通常是快速磁盘。它必须足够大，并且提供对这些内存映像的直接访问。
+ 为了有效使用CPU，**需要每个进程的执行时间比交换时间长**，而影响交换时间的主要是转移时间。转移时间与所交换的内存空间成正比。
+ 如果换出进程，必须确保该进程是完全处于空闲状态。
+ 普通的交换使用不多，但交换策略的某些变种在许多系统中（如 UNIX 系统）仍发挥作用。

#### 内存连续分配管理方式

连续分配方式，是指为一个用户程序分配一个连续的内存空间。它主要包括单一连续分配、固定分区分配和动态分区分配。

> 单一连续分配

内存在此方式下分为系统区和用户区，系统区仅提供给操作系统使用，通常在低地址部分；用户区是为用户提供的、除系统区之外的内存空间。这种方式无需进行内存保护。

> 固定分区分配

将用户内存空间划分为若干个固定大小的区域，每个分区只装入一道作业。当有空闲分区时，便可以再从外存的后备作业队列中,选择适当大小的作业装入该分区，如此循环。

这种分区方式存在两个问题：一是程序可能太大而放不进任何一个分区中，这时用户不得不使用覆盖技术来使用内存空间；二是主存利用率低，当程序小于固定分区大小时，也占用了一个完整的内存分区空间，这样分区内部有空间浪费，这种现象称为内部碎片。

> 动态分区分配

(与 JVM 垃圾回收进行对比)
动态分区分配又称为可变分区分配，是一种动态划分内存的分区方法。这种分区方法不预先将内存划分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统中分区的大小和数目是可变的。

在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略，考虑以下几种算法：

+ **首次适应(First  Fit)算法**：空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。
+ 最佳适应(Best  Fit)算法：空闲分区按容量递增形成分区链，找到第一个能满足要求的空闲分区。
+ 最坏适应(Worst  Fit)算法：又称最大适应(Largest Fit)算法，空闲分区以容量递减的次序链接。找到第一个能满足要求的空闲分区，也就是挑选出最大的分区。
+ 邻近适应(Next  Fit)算法：又称循环首次适应算法，由首次适应算法演变而成。不同之处是分配内存时从上次查找结束的位置开始继续查找。

在这几种方法中，首次适应算法不仅是最简单的，而且通常也是最好和最快的。

#### 内存非连续分配管理方式

非连续分配**允许一个程序分散地装入到不相邻的内存分区中**，根据分区的大小是否固定分为*分页存储管理方式*和*分段存储管理方式*。

分页存储管理方式中，又根据运行作业时是否要把作业的所有页面都装入内存才能运行分为*基本分页存储管理方式*和*请求分页存储管理方式*。
> 基本分页存储管理方式

固定分区会产生内部碎片，动态分区会产生外部碎片，这两种技术对内存的利用率都比较低。我们希望内存的使用能尽量避免碎片的产生，这就引入了**分页的思想**：把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。

分页的方法从形式上看，像分区相等的固定分区技术，分页管理不会产生外部碎片。但它又有本质的不同点：**块的大小相对分区要小很多，而且进程也按照块进行划分，进程运行时按块申请主存可用空间并执行**。这样，进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片，所以尽管会产生内部碎片，但是这种碎片相对于进程来说也是很小的。

> 分页存储的几个概念：

a. 页面和页面大小。进程中的块称为页(Page)，内存中的块称为页框（Page Frame，或页帧）。外存也以同样的单位进行划分，直接称为块(Block)。进程在执行时需要申请主存空间，就是要为每个页面分配主存中的可用页框，这就产生了页和页框的一一对应。

为方便地址转换，页面大小应是 2 的整数幂。同时页面大小应该适中，如果页面太小，会使进程的页面数过多，这样页表就过长，占用大量内存，而且也会增加硬件地址转换的开销，降低页面换入/换出的效率；页面过大又会使页内碎片增大，降低内存的利用率。所以页面的大小应该适中，考虑到耷间效率和时间效率的权衡。

b. 地址结构。分页存储管理的逻辑地址结构如图:  
![分页存储管理的地址结构](https://upload-images.jianshu.io/upload_images/17260324-ae3369a4148bcd75.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

地址结构包含两部分：前一部分为页号 P，后一部分为页内偏移量W。地址长度为 32 位，其中 0~11 位为页内地址，即每页大小为 4KB ；12~31 位为页号，地址空间最多允许有 2^20 页。

c. 页表。为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表，记录页面在内存中对应的物理块号，页表一般存放在内存中。在配置了页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，页表的作用是实现从页号到物理块号的地址映射。  
![页表的作用](https://upload-images.jianshu.io/upload_images/17260324-4add7d42a713f5e7.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

> 基本地址变换机构

地址变换机构的任务是将逻辑地址转换为内存中物理地址，地址变换是借助于页表实现的。  
![分页存储管理的地址变换机构](https://upload-images.jianshu.io/upload_images/17260324-d659127384c46a08.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

分页管理方式存在的两个主要问题：

+ 每次访存操作都需要进行逻辑地址到物理地址的转换，地址转换过程必须足够快，否则访存速度会降低；
+ 每个进程引入了页表，用于存储映射机制，页表不能太大，否则内存利用率会降低。

> 具有快表的地址变换机构

由上面介绍的地址变换过程可知，若页表全部放在内存中，则存取一个数据或一条指令至少要访问两次内存：一次是访问页表，确定所存取的数据或指令的物理地址，第二次才根据该地址存取数据或指令。显然，这种方法比通常执行指令的速度慢了一半。

为此，在地址变换机构中增设了一个具有并行查找能力的高速缓冲存储器——快表，又称联想寄存器(TLB)，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，主存中的页表也常称为慢表，配有快表的地址变换机构如图所示。  
![具有快表的地址变换机构](https://upload-images.jianshu.io/upload_images/17260324-791870bfe60619f6.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

一般快表的命中率可以达到90%以上，这样，分页带来的速度损失就降低到10%以下。快表的有效性是基于著名的局部性原理。

> 两级页表

第二个问题：由于引入了分页管理，进程在执行时不需要将所有页调入内存页框中，而只要将保存有映射关系的页表调入内存中即可。但是我们仍然需要考虑页表的大小。

将页表映射的思想进一步延伸，就可以得到二级分页：将页表的10页空间也进行地址映射，建立上一级页表，用于存储页表的映射关系。这里对页表的10个页面进行映射只需要10个页表项，所以上一级页表只需要1页就足够（可以存储 2^10=1024个页表项）。在进程执行时，只需要将这1页的上一级页表调入内存即可，进程的页表和进程本身的页面，可以在后面的执行中再 i 周入内存。

如图所示，这是Intel处理器80x86系列的硬件分页的地址转换过程。在32位系统中，全部32位逻辑地址空间可以分为2^20(4GB/4KB)个页面。这些页面可以再进一步建立顶级页表，需要2^10个顶级页表项进行索引，这正好是一页的大小，所以建立二级页表即可。  
![硬件分页地址转换](https://upload-images.jianshu.io/upload_images/17260324-16bf6072a60de1c0.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

> 基本分段存储管理方式

*分页管理方式是从计算机的角度考虑设计的，以提高内存的利用率，提升计算机的性能*, 且分页通过硬件机制实现，对用户完全透明；而*分段管理方式的提出则是考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长及动态链接等*多方面的需要。

> 分段

段式管理方式按照用户进程中的自然段划分逻辑空间。例如，用户进程由主程序、两个子程序、栈和一段数据组成，于是可以把这个用户进程划分为5个段，每段从0 开始编址，并分配一段连续的地址空间（段内要求连续，段间不要求连续，因此整个作业的地址空间是二维的）。其逻辑地址由段号S与段内偏移量W两部分组成。

在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必须由用户显示提供，在髙级程序设计语言中，这个工作由编译程序完成。

> 段表

每个进程都有一张逻辑空间与内存空间映射的段表，其中每一个段表项对应进程的一个段，段表项记录该段在内存中的起始地址和段的长度。段表的内容如图所示。  
![段表项](https://upload-images.jianshu.io/upload_images/17260324-cafbc752ea8c9aff.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在配置了段表后，执行中的进程可通过查找段表，找到每个段所对应的内存区。

> 段的共享与保护

在分段系统中，段的共享是通过两个作业的段表中相应表项指向被共享的段的同一个物理副本来实现的。当一个作业正从共享段中读取数据时，必须防止另一个作业修改此共享段中的数据。不能修改的代码称为纯代码或可重入代码（它不属于临界资源)，这样的代码和不能修改的数据是可以共享的，而可修改的代码和数据则不能共享。

与分页管理类似，分段管理的保护方法主要有两种：一种是存取控制保护，另一种是地址越界保护。地址越界保护是利用段表寄存器中的段表长度与逻辑地址中的段号比较，若段号大于段表长度则产生越界中断；再利用段表项中的段长和逻辑地址中的段内位移进行比较，若段内位移大于段长，也会产生越界中断。

> 段页式管理方式

页式存储管理能有效地提高内存利用率，而分段存储管理能反映程序的逻辑结构并有利于段的共享。如果将这两种存储管理方法结合起来，就形成了段页式存储管理方式。

在段页式系统中，作业的地址空间首先被分成若干个逻辑段，每段都有自己的段号，然后再将每一段分成若干个大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干个和页面大小相同的存储块，对内存的分配以存储块为单位，如图所示。  
![段页式管理方式](https://upload-images.jianshu.io/upload_images/17260324-61445d8a86078c37.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在进行地址变换时，首先通过段表查到页表起始地址，然后通过页表找到页帧号，最后形成物理地址。如图3-18所示，进行一次访问实际需要三次访问主存，这里同样可以使用快表以加快查找速度，其关键字由段号、页号组成，值是对应的页帧号和保护码。

#### 虚拟内存

刚刚说的内存管理方式有个特点：都要求将一个作业全部装入内存后才能运行。这在作业很大或是作业量很大的时候会出现问题，除了从物理上增加内存容量，还可以从逻辑上扩充容量，这就是虚拟内存。

**当访问虚拟内存时，会通过 MMU（内存管理单元）去匹配对应的物理地址**，而如果虚拟内存的页并不存在于物理内存中，会产生**缺页中断**，从磁盘中取得缺的页放入内存，如果内存已满，还会根据某种算法将磁盘中的页换出。

> 页面置换算法

页面置换算法和缓存淘汰策略类似。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

1. 最佳 Optimal
   所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。  
   是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。
2. 最近最久未使用 （LRU, Least Recently Used）
   虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。  
   为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面时最近最久未访问的。因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。
3. 最近未使用（NRU, Not Recently Used）
   首先，系统为毎一页面设置了两个状态位。当页面被访问 (读或写) 时设置 R 位; 当页面 (即修改页面) 被写入时设置 M 位。当启动一个进程时，它的所有页面的两个位都由操作系统设置成 0，R 位被定期地 (比如在每次时钟中断时) 清零，以区别最近没有被访问的页面和被访问的页面。  
   当发生缺页中断时，操作系统检査所有的页面并根据它们当前的 R 位和 M 位的值，把它们分为 4 类，NRU 算法随机地从类编号最小的非空类中挑选一个页面淘汰之。
4. 先进先出（FIFO, First In First Out）
   选择换出的页面是最先进入的页面。  
   该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。
5. 改进型FIFO (Second Chance Page Replacement Algorithm)
   这种算法是在FIFO的基础上，为了避免置换出经常使用的页，增加一个标志位R，如果最近使用过将 R 置1，当页将会淘汰时，如果 R 为1，则不淘汰页，将 R 置0.而那些 R=0 的页将被淘汰时，直接淘汰。这种算法避免了经常被使用的页被淘汰。
6. 时钟替换 (Clock Page Replacement Algorithm)
   虽然改进型 FIFO 算法避免置换出常用的页，但由于需要经常移动页，效率并不高。因此在改进型 FIFO 算法的基础上，将队列首位相连形成一个环路，当缺页中断产生时，从当前位置开始找R=0的页，而所经过的 R=1 的页被置 0，并不需要移动页。
